{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание: подготовка и обучение WGAN-GP\n",
        "\n"
      ],
      "metadata": {
        "id": "wx7CvjNo-qVd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Разбалловка:\n",
        "\n",
        "- Код генератора (5 баллов)\n",
        "- Код критика (7 баллов)\n",
        "- Gradient penalty (3 балла)\n",
        "- Код обучения (5 баллов)\n",
        "- Оценка fid:\n",
        "    *   <= 60 -- 10б\n",
        "    *   <= 85 -- 8б\n",
        "    *   <= 110 -- 6б\n",
        "    *   <= 135 -- 4б\n",
        "    *   <= 160 -- 2б\n",
        "    *   <= 200 -- 0б\n",
        "\n"
      ],
      "metadata": {
        "id": "i7AFlphK-yj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовка данных"
      ],
      "metadata": {
        "id": "2G3BTuGiYIvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка необходимых библиотек\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import tempfile\n",
        "from PIL import Image\n",
        "\n"
      ],
      "metadata": {
        "id": "JlTKOtLSYL5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка seed для воспроизводимости и проверка доступности куды\n",
        "torch.manual_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPBQurjkaK5a",
        "outputId": "69356c94-732b-46b8-d7bc-b5f554a6e9a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка kagglehub, если вы работаете не в Google Colab\n",
        "!pip install kagglehub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js6skmzYYTlk",
        "outputId": "9e40a63d-d54c-4522-e0bd-d9ac4af5fffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы будем работать с датасетом с аниме лицами с кагла. Датасет можно найти [тут](https://www.kaggle.com/datasets/splcher/animefacedataset).\n",
        "\n",
        "Ниже мы приведём способо скачивания и подгрузки данных, однако вы можете также напряму скачать датасет с кагла и перенести его в интересующую папку."
      ],
      "metadata": {
        "id": "G4ugEC5D6w58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Укажите путь к папке, куда хотите скачать датасет\n",
        "target_folder = '/content/faces'\n",
        "os.makedirs(target_folder, exist_ok=True)\n",
        "\n",
        "# Загрузка последней версии датасета\n",
        "path = kagglehub.dataset_download(\"splcher/animefacedataset\")\n",
        "\n",
        "# Перемещение загруженных файлов в целевую папку\n",
        "for file in os.listdir(path):\n",
        "    shutil.move(os.path.join(path, file), os.path.join(target_folder, file))\n",
        "\n",
        "print(\"Датасет успешно загружен в папку:\", target_folder)"
      ],
      "metadata": {
        "id": "QELeUbvPdWWc",
        "outputId": "7bccf0a7-0f3d-4f93-f1f1-d5c7a8484a9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'animefacedataset' dataset.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[Errno 30] Read-only file system: '/kaggle/input/animefacedataset/images'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    846\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 18] Invalid cross-device link: '/kaggle/input/animefacedataset/images' -> '/content/faces/images'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3767203138.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Перемещение загруженных файлов в целевую папку\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Датасет успешно загружен в папку:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    863\u001b[0m             copytree(src, real_dst, copy_function=copy_function,\n\u001b[1;32m    864\u001b[0m                      symlinks=True)\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0mcopy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror, onexc, dir_fd)\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0m_rmtree_safe_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0;31m# Close any file descriptors still on the stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(stack, onexc)\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0monexc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m _use_fd_functions = ({os.open, os.stat, os.unlink, os.rmdir} <=\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(stack, onexc)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m                 \u001b[0monexc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(stack, onexc)\u001b[0m\n\u001b[1;32m    696\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0monexc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/kaggle/input/animefacedataset/images'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Отрисовка сэмплов\n",
        "# Посмотрим на один батч изображений\n",
        "data_iter = iter(dataloader)\n",
        "images, _ = next(data_iter)\n",
        "\n",
        "# Отключение нормализации для отображения (перевод из [-1, 1] в [0, 1])\n",
        "images = images * 0.5 + 0.5\n",
        "\n",
        "# Создание и отображение сетки изображений\n",
        "grid = make_grid(images, nrow=8)\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(np.transpose(grid.numpy(), (1, 2, 0)))\n",
        "plt.axis('off')\n",
        "plt.title('Sampled Anime Images')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "nU1583_ielG-",
        "outputId": "a32ad56f-bcf7-44b7-c8ac-bdd11c05c783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dataloader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2238295861.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Отрисовка сэмплов\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Посмотрим на один батч изображений\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WGAN with gradient penalty (8 баллов)\n",
        "\n",
        "Давайте вспомним, какую задачу мы вообще решаем, что такое WGAN with gradient penalty и как его построить.\n",
        "\n"
      ],
      "metadata": {
        "id": "CYxH6ZgN7_Is"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WGAN\n",
        "\n",
        "Для начала напомним, что такое WGAN. На лекции вы обсуждали, что у классического гана, который обучался со следующим функционалом:\n",
        "\n",
        "$$\\min_\\mathcal{G} \\max_{\\mathcal{D}} \\mathcal{L}(\\mathcal{G}, \\mathcal{D}) = \\mathbb{E}_{x \\sim X} [\\log \\mathcal{D}(x)] + \\mathbb{E}_{z \\sim Z} [\\log (1 - \\mathcal{D}(\\mathcal{G}(z)))]$$\n",
        "\n",
        "где $\\mathcal{G}$ -- генератор, принимающий на вход латент $z$ и генерирует картинку, а $\\mathcal{D}$ -- дискриминатор, который по сути работает как бинарный классификатор, выдавая **вероятности** для реальных и сгенерированных данных.\n",
        "\n",
        "В процессе оптимизации мы делаем несколько шагов, обновляя дискриминатор делая шаг по градиенту:\n",
        "\n",
        "$$\\nabla_{\\phi} \\frac{1}{n} \\sum_{i=1}^{n}\\left[\\log D_{\\phi}\\left(x_{i}\\right)+\\log \\left(1-D_{\\phi}\\left(G_{\\theta}\\left(z_{i}\\right)\\right)\\right)\\right]$$\n",
        "\n",
        "И затем делаем шаг обновления генератора:\n",
        "\n",
        "$$\n",
        "\\nabla_{\\theta} \\left[\\frac{1}{n} \\sum_{i=1}^{n} \\log \\left(1-D_{\\phi^{*}}\\left(G_{\\theta}\\left(z_{i}\\right)\\right)\\right) \\right]\n",
        "$$\n",
        "\n",
        "Однако у такой модели есть ряд проблем.\n",
        "\n",
        "В случае, если мы очень хорошо обучили дискриминатор, значения под логарифмом будет близко к 1 при обучении генератора, а значит градиенты будут практически нулевыми и модель обучаться не будет.\n",
        "\n",
        "Такой лосс также не учитывает, насколько близко находятся распределения реальных и сгенерированных данных."
      ],
      "metadata": {
        "id": "uyyzxnpm83hk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Wasserstein GAN (WGAN)** решает эти проблемы, заменяя функцию потерь на расстояние Вассертшейна или Earth Mover's Distance. Этот лосс измеряет минимальную \"стоимость\" перемещения данных, чтобы преобразовать одно распределение в другое.\n",
        "\n",
        "$$W_1(p_{\\text{data}}, p_{gen}) = \\inf_{\\gamma \\in \\Pi(p_{\\text{data}}, p_{gen})} \\mathbb{E}_{(x, y) \\sim \\gamma} [| x - y |]$$\n",
        "\n",
        "Формула выглядит страшно, но в таком виде она нам и не понадобится. На самом деле она сводится к следующему:\n",
        "\n",
        "$$  W_1(p_{\\text{data}}, p_{\\mathcal{G}}) = \\sup_{\\| f \\|_L \\leq 1} \\left( \\mathbb{E}_{x \\sim p_{\\text{data}}} [f(x)] - \\mathbb{E}_{y \\sim p_{gen}} [f(y)] \\right)  $$\n",
        "\n",
        "Дискриминатор превращается в **критика**, который теперь не является обычным бинарным классификатором и выдаёт не вероятность, а скалярное значение, оценивающее \"реалистичность\" изображения. Также наш **критик** должен удовлетворять условию Липшевости.\n",
        "\n",
        "\n",
        "\n",
        "> С математической точки зрения, функция f называется L-липшицевой, если для любых двух точек $x_1$ и $x_2$ в её области определения выполняется следующее неравенство: $∣f(x_1 )−f(x_2 )∣ \\leq L⋅∣x_1 − x_2 ∣$.\n",
        "\n",
        "То есть по сути наша фукция не должна **меняться слишком быстро.**\n",
        "\n",
        "В оригинальной статье предлагается делать clipping для градиентов $w \\in [c, c]$ где $w$ - параметры критика, а $c$ - некоторое маленькое число, чтобы выполнялось данное условие.\n",
        "\n",
        "Более подробно и математически строго про WGAN можно почитать в [оригинальной статье](https://arxiv.org/pdf/1701.07875).\n",
        "\n"
      ],
      "metadata": {
        "id": "SCzDfRnuJUXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Wasserstein GAN with gradient penalty (WGAN -- GP)**\n",
        "\n",
        "Предложенный в оригинальной статье метод по ограничению весов часто приводит к нестабильности обучения и плохой сходимости.\n",
        "\n",
        "**Gradient Penalty** добавляет штраф за отклонение нормы градиента от 1, что делает обучение критика более стабильным и позволяет ему моделировать более сложные функции без жестких ограничений на веса.\n",
        "\n",
        "$$ \\mathcal{L} = \\mathbb{E}_{\\hat{x} \\sim p_{\\hat{x}}} \\left[ (| \\nabla_{\\hat{x}} \\mathcal{D}(\\hat{x}) |_2 - 1)^2 \\right] $$\n",
        "\n",
        "Что такое $\\hat{x}$:\n",
        "\n",
        "$$ \\hat{x} = \\alpha x + (1 - \\alpha) y, \\quad \\alpha \\sim U[0, 1]$$\n",
        "\n",
        "По сути это интерполяция между реальными и сгенерированными данным, где $x \\sim p_{data}$ и $y\\sim p_{gen}$.\n",
        "\n",
        "Более подробно о градиентном штрафе можно почитать в [оригинальной статье](https://arxiv.org/pdf/1704.00028).\n",
        "\n",
        "\n",
        "Давайте теперь построим генератор и критика для обучения."
      ],
      "metadata": {
        "id": "9DBF8UoGOBsy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Генератор (5 баллов)\n",
        "\n",
        "Подготовьте код генератора. Рекомендуем сделать блочную структуру, где каждый блок содержит:\n",
        "\n",
        "```\n",
        " nn.ConvTranspose2d\n",
        " nn.BatchNorm2d\n",
        " nn.ReLU\n",
        "```\n",
        "Однако вы можете сами выбрать архитектуру, которая вам покажется лучше :)\n"
      ],
      "metadata": {
        "id": "abPwB4nmOLSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Генератор\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=128, channels_img=3, features_g=64):\n",
        "        super(Generator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # Вход: N x z_dim x 1 x 1\n",
        "            YOUR CODE IS HERE\n",
        "            # Out: N x (features_g*8) x 4 x 4\n",
        "\n",
        "            YOUR CODE IS HERE\n",
        "            # Out: N x (features_g*4) x 8 x 8\n",
        "\n",
        "            YOUR CODE IS HERE\n",
        "            # Out: N x (features_g*2) x 16 x 16\n",
        "\n",
        "            YOUR CODE IS HERE\n",
        "            # Out: N x features_g x 32 x 23\n",
        "\n",
        "            YOUR CODE IS HERE\n",
        "            nn.Tanh(),\n",
        "            # Out: N x 3 x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        YOUR CODE IS HERE\n"
      ],
      "metadata": {
        "id": "eKm3S6ojgdsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Критик (7 баллов)\n",
        "\n",
        "Теперь давайте построим критика.\n",
        "\n",
        "Для остроения критика используйте\n",
        "\n",
        "```\n",
        "nn.Conv2d\n",
        "nn.InstanceNorm2d\n",
        "nn.LeakyReLU\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "h4ltqFK_RXGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Критик\n",
        "\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self, channels_img=3, features_d=128):\n",
        "        super(Critic, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # Вход: N x 3 x 64 x 64\n",
        "            YOUR CODE IS HERE\n",
        "\n",
        "    def forward(self, x):\n",
        "        YOUR CODE IS HERE"
      ],
      "metadata": {
        "id": "DJ5jgpsTRXbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Лосс для обучения (3 балла)"
      ],
      "metadata": {
        "id": "n_yIP1xYSFmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте теперь подготовим лосс для обучения.\n",
        "\n",
        "Напомним:\n",
        "\n",
        "1. $ \\hat{x} = \\alpha x + (1 - \\alpha) y, \\quad \\alpha \\sim U[0, 1]$\n",
        "  где $x \\sim p_{data}$ и $y\\sim p_{gen}$.\n",
        "\n",
        "2. $ \\mathcal{L} = \\mathbb{E}_{\\hat{x} \\sim p_{\\hat{x}}} \\left[ (| \\nabla_{\\hat{x}} \\mathcal{D}(\\hat{x}) |_2 - 1)^2 \\right] $\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2VJMBsi-SJB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient_penalty(critic, real, fake, device, lambda_gp):\n",
        "    \"\"\"\n",
        "    Computes the gradient penalty for WGAN-GP to enforce 1-Lipschitz continuity.\n",
        "\n",
        "    Args:\n",
        "        critic (nn.Module): Critic model that takes images and outputs a scalar.\n",
        "        real (torch.Tensor): Real images from the dataset [batch_size, channels, height, width].\n",
        "        fake (torch.Tensor): Generated images [batch_size, channels, height, width].\n",
        "        device (torch.device): Device (CPU or GPU).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Scalar gradient penalty.\n",
        "    \"\"\"\n",
        "    batch_size, channels, height, width = real.shape\n",
        "\n",
        "    # Создаём интерполированные данные с помощью torch.rand для сэмлплирования alpha\n",
        "    YOUR CODE IS HERE (1 БАЛЛ)\n",
        "    x_hat = x_hat.requires_grad_(True)\n",
        "\n",
        "    # Предсказания критика\n",
        "    YOUR CODE IS HERE (1 БАЛЛ)\n",
        "\n",
        "    # Подготовка градиентов\n",
        "    grad_outputs = torch.ones_like(disc_interpolates, device=device)\n",
        "\n",
        "    # Подсчёт градиентов\n",
        "    gradients = torch.autograd.grad(\n",
        "        outputs=disc_interpolates,\n",
        "        inputs=x_hat,\n",
        "        grad_outputs=grad_outputs,\n",
        "        create_graph=True,\n",
        "        retain_graph=True\n",
        "    )[0]\n",
        "    gradients = gradients.view(batch_size, -1)\n",
        "\n",
        "    # Вычисление норм градиентов\n",
        "    gradient_norm = gradients.norm(2, dim=1)\n",
        "\n",
        "    # Вычисление лосса\n",
        "    penalty = YOUR CODE IS HERE (1 БАЛЛ)\n",
        "\n",
        "    return penalty * lambda_gp"
      ],
      "metadata": {
        "id": "wy7JhTmbpmir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовим несколько вспомогательных функций"
      ],
      "metadata": {
        "id": "Y2y6Lb0Mwbkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_output_directories(output_dir):\n",
        "    \"\"\"Создает необходимые директории для сохранения результатов обучения.\"\"\"\n",
        "    images_dir = os.path.join(output_dir, 'images')\n",
        "    weights_dir = os.path.join(output_dir, 'weights')\n",
        "    os.makedirs(images_dir, exist_ok=True)\n",
        "    os.makedirs(weights_dir, exist_ok=True)\n",
        "    return images_dir, weights_dir"
      ],
      "metadata": {
        "id": "8pbPWVp0wd8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_and_plot_samples(generator, fixed_noise, epoch, images_dir):\n",
        "    \"\"\"Генерирует изображения, сохраняет их и отрисовывает.\"\"\"\n",
        "    with torch.no_grad():\n",
        "        generator.eval()\n",
        "        fake = generator(fixed_noise).detach().cpu()\n",
        "        generator.train()\n",
        "\n",
        "        # Денормализация: [-1, 1] -> [0, 1]\n",
        "        fake = fake * 0.5 + 0.5\n",
        "\n",
        "        # Сохранение сетки изображений\n",
        "        image_path = os.path.join(images_dir, f'fake_samples_epoch_{epoch:03d}.png')\n",
        "        save_image(fake, image_path, nrow=8)\n",
        "\n",
        "        # Отображение\n",
        "        grid = make_grid(fake, nrow=8)\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.imshow(np.transpose(grid.numpy(), (1, 2, 0)))\n",
        "        plt.title(f\"Сгенерированные изображения: Эпоха {epoch}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "q_eJNpQFwgi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model_weights(netG, netC, epoch, weights_dir):\n",
        "    \"\"\"Сохраняет веса Генератора и Критика.\"\"\"\n",
        "    torch.save(netG.state_dict(), os.path.join(weights_dir, f'netG_epoch_{epoch:03d}.pth'))\n",
        "    torch.save(netC.state_dict(), os.path.join(weights_dir, f'netD_epoch_{epoch:03d}.pth'))"
      ],
      "metadata": {
        "id": "4EFv7abMwjLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_losses(gen_losses, crit_losses):\n",
        "    \"\"\"Отрисовывает графики лоссов после завершения обучения.\"\"\"\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(gen_losses, label='Generator Loss', color='blue')\n",
        "    plt.plot(crit_losses, label='Critic Loss', color='red')\n",
        "    plt.xlabel(\"Эпохи\")\n",
        "    plt.ylabel(\"Лосс (Wasserstein Distance + GP)\")\n",
        "    plt.title(\"Лосс Генератора и Критика во время обучения\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ZndAYWPmwmO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовим функцию обучения (5 баллов)\n",
        "\n",
        "Помимо ограничения на градиенты, не забываем использовать лосс WGAN.\n",
        "\n",
        "\n",
        "$$ L = - \\mathbb{E}_{x \\sim p_{\\text{data}}} [\\mathcal{D}(x)] + \\mathbb{E}_{z \\sim p_z(z)} [\\mathcal{D}(\\mathcal{G}(z))] + \\lambda \\mathbb{E}_{\\hat{x} \\sim p_{\\hat{x}}} \\left[ (| \\nabla_{\\hat{x}} \\mathcal{D}(\\hat{x}) |_2 - 1)^2 \\right] $$\n"
      ],
      "metadata": {
        "id": "sgxqd15OZiTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_wgan_gp(dataloader, gen, crit, opt_gen, opt_crit, num_epochs, z_dim, device, lambda_gp=10, critics_per_gen=5, output_dir=\"output\"):\n",
        "    \"\"\"\n",
        "    Обучает модель WGAN-GP, выводит лоссы, сохраняет картинки и веса каждую эпоху,\n",
        "    и отрисовывает финальный график лоссов.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Инициализация\n",
        "    gen_losses = []\n",
        "    crit_losses = []\n",
        "    fixed_noise = torch.randn(64, z_dim, 1, 1, device=device)\n",
        "    images_dir, weights_dir = setup_output_directories(output_dir)\n",
        "\n",
        "    print(f\"Начало обучения WGAN-GP на {num_epochs} эпох...\")\n",
        "\n",
        "    # 2. Основной цикл обучения\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        epoch_g_loss = 0.0\n",
        "        epoch_c_loss = 0.0\n",
        "        num_batches = len(dataloader)\n",
        "        batch_iterator = tqdm(dataloader, desc=f\"Эпоха {epoch}/{num_epochs}\", leave=False)\n",
        "\n",
        "        for i, (real_images, _) in enumerate(batch_iterator):\n",
        "            real_images = real_images.to(device)\n",
        "            batch_size = real_images.size(0)\n",
        "\n",
        "            # Обучение Критика\n",
        "            for _ in range(critics_per_gen):\n",
        "                opt_crit.zero_grad()\n",
        "\n",
        "\n",
        "                fake_images = YOUR CODE IS HERE\n",
        "\n",
        "                crit_real = crit(real_images).view(-1)\n",
        "                crit_fake = crit(fake_images).view(-1)\n",
        "\n",
        "                # Gradient Penalty\n",
        "                gp = YOUR CODE IS HERE\n",
        "\n",
        "                # W-Loss + GP\n",
        "                crit_loss = YOUR CODE IS HERE\n",
        "\n",
        "                crit_loss.backward()\n",
        "                opt_crit.step()\n",
        "\n",
        "                epoch_c_loss += crit_loss.item() / critics_per_gen\n",
        "\n",
        "            # Обучение Генератора\n",
        "            opt_gen.zero_grad()\n",
        "\n",
        "            fake_images = YOUR CODE IS HERE\n",
        "\n",
        "            # G-Loss: -E[D(G(z))]\n",
        "\n",
        "            gen_loss = YOUR CODE IS HERE\n",
        "\n",
        "            gen_loss.backward()\n",
        "            opt_gen.step()\n",
        "\n",
        "            epoch_g_loss += gen_loss.item() # Накапливаем лосс\n",
        "\n",
        "            batch_iterator.set_postfix(CritLoss=f'{crit_loss.item():.4f}', GenLoss=f'{gen_loss.item():.4f}')\n",
        "\n",
        "        # 3. Действия в конце эпохи\n",
        "        avg_g_loss = epoch_g_loss / num_batches\n",
        "        avg_c_loss = epoch_c_loss / num_batches\n",
        "        gen_losses.append(avg_g_loss)\n",
        "        crit_losses.append(avg_c_loss)\n",
        "\n",
        "        print(f\"\\n--- Эпоха {epoch}/{num_epochs} ---\\nСредний Лосс Критика: {avg_c_loss:.4f}, Средний Лосс Генератора: {avg_g_loss:.4f}\")\n",
        "\n",
        "        # Сохранение и отрисовка\n",
        "        save_and_plot_samples(gen, fixed_noise, epoch, images_dir)\n",
        "        save_model_weights(gen, crit, epoch, weights_dir)\n",
        "        print(f\"Изображения и веса сохранены для эпохи {epoch} в {output_dir}.\")\n",
        "\n",
        "    # 4. Финальная валидация\n",
        "    print(\"\\nОбучение завершено. Отрисовка графиков потерь...\")\n",
        "    plot_training_losses(gen_losses, crit_losses)\n",
        "\n",
        "    return gen, crit, gen_losses, crit_losses"
      ],
      "metadata": {
        "id": "ibXA5JTbwIkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация моделей\n",
        "generator = Generator().to(device)\n",
        "critic = Critic().to(device)"
      ],
      "metadata": {
        "id": "Tppz52fVwpKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Задайте все необходимые гиперпараметры\n",
        "YOUR CODE IS HERE\n",
        "(рекомендуем хотя бы 15 эпох)\n",
        "\n",
        "# Оптимизаторы\n",
        "opt_gen = optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
        "opt_crit = optim.Adam(critic.parameters(), lr=lr, betas=(b1, b2))"
      ],
      "metadata": {
        "id": "m8fVv8UbwpMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen, crit, gen_losses, crit_losses = train_wgan_gp(dataloader, generator, critic, opt_gen, opt_crit, num_epochs, z_dim, device, lambda_gp=10, critics_per_gen=5, output_dir=\"output\")"
      ],
      "metadata": {
        "id": "bvbYTOgfXRcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Валидация обученной модели"
      ],
      "metadata": {
        "id": "tULU2pDPLX65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для валидации будем использовать библиотеку `clean-fid`"
      ],
      "metadata": {
        "id": "Qna6FP-iLa42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install clean-fid"
      ],
      "metadata": {
        "id": "9OhcHVKJLeVT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9c73e7d-ba7e-4ada-f117-4268fecb5fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting clean-fid\n",
            "  Downloading clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from clean-fid) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from clean-fid) (0.24.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.12/dist-packages (from clean-fid) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from clean-fid) (1.16.3)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.12/dist-packages (from clean-fid) (4.67.1)\n",
            "Requirement already satisfied: pillow>=8.1 in /usr/local/lib/python3.12/dist-packages (from clean-fid) (11.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from clean-fid) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->clean-fid) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->clean-fid) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->clean-fid) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->clean-fid) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->clean-fid) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->clean-fid) (3.0.3)\n",
            "Downloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: clean-fid\n",
            "Successfully installed clean-fid-0.1.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load('/content/output/weights/netG_epoch_01.pth', map_location=device)\n",
        "\n",
        "# Загрузим веса (не забудьте поправить путь на корректный)\n",
        "generator.load_state_dict(state_dict)\n",
        "\n",
        "gen.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS538B2v8Ifz",
        "outputId": "a3a6fb5f-06d8-402b-9489-5b3cb67938d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (net): Sequential(\n",
              "    (0): ConvTranspose2d(128, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (11): ReLU()\n",
              "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (13): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cleanfid import fid\n",
        "\n",
        "def get_images_to_fid_format(images_list):\n",
        "    \"\"\"\n",
        "    Преобразование картинок для clean-fid формата\n",
        "    \"\"\"\n",
        "    all_images = torch.cat(images_list, dim=0)\n",
        "    all_images = all_images * 0.5 + 0.5\n",
        "    all_images = all_images.mul(255).add(0.5).clamp(0, 255).permute(0, 2, 3, 1).to('cpu', torch.uint8).numpy()\n",
        "    return all_images\n",
        "\n",
        "def save_images_to_folder(image_array, folder_path, max_to_save=None):\n",
        "    \"\"\"\n",
        "    Сохранение изображений\n",
        "    \"\"\"\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "    num_images = image_array.shape[0]\n",
        "    if max_to_save is not None and max_to_save < num_images:\n",
        "        images_to_process = image_array[:max_to_save]\n",
        "        print(f\"Сохраняем первые {max_to_save} изображений в {folder_path}...\")\n",
        "    else:\n",
        "        images_to_process = image_array\n",
        "        print(f\"Сохраняем все {num_images} изображений в {folder_path}...\")\n",
        "\n",
        "    for i in tqdm(range(images_to_process.shape[0]), desc=f\"Сохранение в {os.path.basename(folder_path)}\"):\n",
        "        img = Image.fromarray(images_to_process[i])\n",
        "        img.save(os.path.join(folder_path, f\"{i:05d}.png\"))\n",
        "\n",
        "\n",
        "def calculate_final_fid_fixed(\n",
        "    trained_gen,\n",
        "    dataloader,\n",
        "    z_dim,\n",
        "    device,\n",
        "    num_samples=10000,\n",
        "    save_generated_path=None,\n",
        "    save_real_path=None,\n",
        "    max_saved_images=100\n",
        "):\n",
        "    \"\"\"\n",
        "    Собирает реальные и фейковые изображения, преобразует их,\n",
        "    сохраняет во временные папки для FID и опционально сохраняет\n",
        "    изображения в постоянные папки.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Сбор реальных изображений\n",
        "    print(\"Собираем реальные изображения...\")\n",
        "    real_images_list = []\n",
        "    for images, _ in dataloader:\n",
        "        real_images_list.append(images.cpu())\n",
        "        if len(real_images_list) * dataloader.batch_size >= num_samples:\n",
        "             break\n",
        "    real_images_array = get_images_to_fid_format(real_images_list)[:num_samples]\n",
        "\n",
        "    if save_real_path:\n",
        "        print(f\"\\nОбнаружен save_real_path. Сохраняем реальные изображения в: {save_real_path}\")\n",
        "        # Сохраняем только часть, определенную max_saved_images\n",
        "        save_images_to_folder(real_images_array, save_real_path, max_to_save=max_saved_images)\n",
        "        print(\"Сохранение реальных изображений завершено.\")\n",
        "\n",
        "    # 2. Генерация фейковых изображений\n",
        "    print(f\"\\nГенерируем {num_samples} фейковых изображений...\")\n",
        "    trained_gen.eval()\n",
        "    fake_images_list = []\n",
        "    batch_size = dataloader.batch_size\n",
        "\n",
        "    for i in tqdm(range(0, num_samples, batch_size)):\n",
        "        current_batch_size = min(batch_size, num_samples - i)\n",
        "        noise = torch.randn(current_batch_size, z_dim, 1, 1, device=device)\n",
        "        with torch.no_grad():\n",
        "            fake_batch = trained_gen(noise).cpu()\n",
        "        fake_images_list.append(fake_batch)\n",
        "\n",
        "    fake_images_array = get_images_to_fid_format(fake_images_list)\n",
        "\n",
        "    if save_generated_path:\n",
        "        print(f\"\\nОбнаружен save_generated_path. Сохраняем сгенерированные изображения в: {save_generated_path}\")\n",
        "        # Сохраняем только часть, определенную max_saved_images\n",
        "        save_images_to_folder(fake_images_array, save_generated_path, max_to_save=max_saved_images)\n",
        "        print(\"Сохранение сгенерированных изображений завершено.\")\n",
        "\n",
        "    # 3. Расчет FID: ИСПОЛЬЗУЕМ ВРЕМЕННЫЕ ПАПКИ\n",
        "    print(\"\\nНачинаем расчет FID...\")\n",
        "\n",
        "    with tempfile.TemporaryDirectory() as real_dir, tempfile.TemporaryDirectory() as fake_dir:\n",
        "\n",
        "        # Для FID сохраняем все необходимые num_samples изображений\n",
        "        print(\"Сохраняем реальные изображения во временную папку для FID...\")\n",
        "        save_images_to_folder(real_images_array, real_dir, max_to_save=None)\n",
        "\n",
        "        print(\"Сохраняем фейковые изображения во временную папку для FID...\")\n",
        "        save_images_to_folder(fake_images_array, fake_dir, max_to_save=None)\n",
        "\n",
        "        fid_value = fid.compute_fid(\n",
        "            real_dir,\n",
        "            fake_dir,\n",
        "            model_name=\"inception_v3\",\n",
        "            device=device,\n",
        "            verbose=True\n",
        "        )\n",
        "        return fid_value\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NQ5LKBsnexIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_fid_score = calculate_final_fid_fixed(\n",
        "    trained_gen=generator,\n",
        "    dataloader=dataloader,\n",
        "    z_dim=z_dim,\n",
        "    device=device,\n",
        "    num_samples=10000,\n",
        "    save_generated_path=\"generated_samples\",\n",
        "    save_real_path=\"real_samples\",\n",
        "    max_saved_images=100\n",
        ")\n",
        "final_fid_score"
      ],
      "metadata": {
        "id": "3z-c8KGK_7Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1UgO2Gb197UW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}